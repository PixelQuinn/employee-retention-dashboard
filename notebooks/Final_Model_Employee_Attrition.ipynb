{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Attrition Prediction: Final Notebook\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates the end-to-end process of using a Random Forest model to predict employee attrition. It incorporates the preprocessed data, evaluates the saved best-performing model, and extracts actionable insights.\n",
    "\n",
    "## Workflow:\n",
    "1. Data Preparation: Load and preprocess the dataset.\n",
    "2. Model Reloading: Load the saved best Random Forest model.\n",
    "3. Evaluation: Assess the model's performance on the test set.\n",
    "4. Interpretation: Analyze feature importance and derive insights.\n",
    "5. Conclusion: Summarize findings and discuss business implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment set up successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Environment set up successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we prepare the dataset for modeling by performing the following steps:\n",
    "1. Load the pre-engineered dataset (`engineered_dataset.csv`).\n",
    "2. Inspect the dataset for structure, missing values, and class imbalance.\n",
    "3. Encode categorical features using one-hot encoding.\n",
    "4. Split the dataset into training and testing sets.\n",
    "5. Address the class imbalance in the target variable using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1470, 36)\n",
      "\n",
      "First Five Rows:\n",
      "   Age  Attrition     BusinessTravel  DailyRate              Department  DistanceFromHome  Education EducationField  EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel                JobRole  JobSatisfaction MaritalStatus  MonthlyIncome  MonthlyRate  NumCompaniesWorked OverTime  PercentSalaryHike  PerformanceRating  RelationshipSatisfaction  StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  RoleStability  OverTime_Binary  OT_WorkLifeImpact  SeniorityImpact  SatisfactionBalance\n",
      "0   41          1      Travel_Rarely       1102                   Sales                 1          2  Life Sciences                        2  Female          94               3         2        Sales Executive                4        Single           5993        19479                   8      Yes                 11                  3                         1                 0                  8                      0                1               6                   4                        0                     5       0.571429                1           0.999990         0.749999                    4\n",
      "1   49          0  Travel_Frequently        279  Research & Development                 8          1  Life Sciences                        3    Male          61               2         2     Research Scientist                2       Married           5130        24907                   1       No                 23                  4                         4                 1                 10                      3                3              10                   7                        1                     7       0.636364                0           0.000000         0.999999                    6\n",
      "2   37          1      Travel_Rarely       1373  Research & Development                 2          2          Other                        4    Male          92               2         1  Laboratory Technician                3        Single           2090         2396                   6      Yes                 15                  3                         2                 0                  7                      3                3               0                   0                        0                     0       0.000000                1           0.333332         0.000000                    9\n",
      "3   33          0  Travel_Frequently       1392  Research & Development                 3          4  Life Sciences                        4  Female          56               3         1     Research Scientist                3       Married           2909        23159                   1      Yes                 11                  3                         3                 0                  8                      3                3               8                   7                        3                     0       0.777778                1           0.333332         0.999999                    9\n",
      "4   27          0      Travel_Rarely        591  Research & Development                 2          1        Medical                        1    Male          40               3         1  Laboratory Technician                2       Married           3468        16632                   9       No                 12                  3                         4                 1                  6                      3                3               2                   2                        2                     2       0.666667                0           0.000000         0.333333                    6\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../data/engineered_dataset.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nFirst Five Rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "Age                         0\n",
      "Attrition                   0\n",
      "BusinessTravel              0\n",
      "DailyRate                   0\n",
      "Department                  0\n",
      "DistanceFromHome            0\n",
      "Education                   0\n",
      "EducationField              0\n",
      "EnvironmentSatisfaction     0\n",
      "Gender                      0\n",
      "HourlyRate                  0\n",
      "JobInvolvement              0\n",
      "JobLevel                    0\n",
      "JobRole                     0\n",
      "JobSatisfaction             0\n",
      "MaritalStatus               0\n",
      "MonthlyIncome               0\n",
      "MonthlyRate                 0\n",
      "NumCompaniesWorked          0\n",
      "OverTime                    0\n",
      "PercentSalaryHike           0\n",
      "PerformanceRating           0\n",
      "RelationshipSatisfaction    0\n",
      "StockOptionLevel            0\n",
      "TotalWorkingYears           0\n",
      "TrainingTimesLastYear       0\n",
      "WorkLifeBalance             0\n",
      "YearsAtCompany              0\n",
      "YearsInCurrentRole          0\n",
      "YearsSinceLastPromotion     0\n",
      "YearsWithCurrManager        0\n",
      "RoleStability               0\n",
      "OverTime_Binary             0\n",
      "OT_WorkLifeImpact           0\n",
      "SeniorityImpact             0\n",
      "SatisfactionBalance         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Shape: (1470, 35)\n",
      "Target Shape: (1470,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "target_column = 'Attrition'  # Replace with your target column name\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "print(\"\\nFeatures Shape:\", X.shape)\n",
    "print(\"Target Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Features Shape: (1470, 49)\n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding for categorical features\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "print(\"\\nEncoded Features Shape:\", X_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Shape: (1176, 49)\n",
      "Testing Set Shape: (294, 49)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining Set Shape:\", X_train.shape)\n",
    "print(\"Testing Set Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      " Attrition\n",
      "0    986\n",
      "1    190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled class distribution:\n",
      " Attrition\n",
      "0    986\n",
      "1    986\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinnreams/Documents/GitHub/employee-retention-dashboard/venv/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "target_column = 'Attrition'\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display resampled class distribution\n",
    "print(\"Original class distribution:\\n\", y_train.value_counts())\n",
    "print(\"\\nResampled class distribution:\\n\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Reloading\n",
    "\n",
    "In this step, we load the pre-trained best-performing Random Forest model from the previous notebook. This ensures consistency in evaluation and avoids retraining.\n",
    "\n",
    "The model was trained with the following best parameters:\n",
    "- `n_estimators`: 300\n",
    "- `max_depth`: 20\n",
    "- `min_samples_split`: 2\n",
    "- `min_samples_leaf`: 1\n",
    "- `class_weight`: 'balanced_subsample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from best_rf_model.joblib.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved best model\n",
    "model_filename = 'best_rf_model.joblib'\n",
    "best_rf_model = joblib.load(model_filename)\n",
    "\n",
    "print(f\"Model loaded successfully from {model_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Parameters:\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=20,\n",
      "                       n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters to confirm correct loading\n",
    "print(\"\\nModel Parameters:\")\n",
    "print(best_rf_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
